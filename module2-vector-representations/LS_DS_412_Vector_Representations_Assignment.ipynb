{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Vector Representations\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 2*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "id": "hyj-f9FDcVFp",
    "outputId": "5dd045fe-6e4c-458c-e2fc-253c3da9c805"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M7bcmqfGXrFG"
   },
   "source": [
    "## 1) *Optional:* Scrape 100 Job Listings that contain the title \"Data Scientist\" from indeed.com\n",
    "\n",
    "At a minimum your final dataframe of job listings should contain\n",
    "- Job Title\n",
    "- Job Description\n",
    "\n",
    "If you choose to not to scrape the data, there is a CSV with outdated data in the directory. Remeber, if you scrape Indeed, you're helping yourself find a job. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.indeed.com/jobs?q=data+science&l=Hialeah%2C+FL&radius=10\"\n",
    "#conducting a request of the stated URL above:\n",
    "page = requests.get(URL)\n",
    "#specifying a desired format of “page” using the html parser - this allows python to read the various components of the page, rather than treating it as one long string.\n",
    "soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "#printing soup in a more structured tree format that makes for easier reading\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Manager, Data Science & Engineering',\n",
       " 'Data Engineer',\n",
       " 'Big Data/ETL Automation Test Engineer',\n",
       " 'AI/Machine Learning/Coding Enthusiast',\n",
       " 'Data Scientist, Data Analytics & AI',\n",
       " 'Associate Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Manager, Data Science & Analytics',\n",
       " 'Artificial Intelligence/Analytics Data Scientist - Consultant',\n",
       " 'Research Data Engineer',\n",
       " 'Sales & Marketing Business Analyst',\n",
       " 'Data Analytics Engineer',\n",
       " 'Data Scientist (Intelligence)',\n",
       " 'Sr. Data Scientist',\n",
       " 'Research Data Engineer']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup): \n",
    "    jobs = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    return(jobs)\n",
    "extract_job_title_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Solid knowledge of current technology data architecture, particularly data lakes and cloud environments.Reporting to the Director of Enterprise Analytics, the…',\n",
       " 'Work with data science teams and with business (data) analysts to refine their data requirements for various data and analytics initiatives.',\n",
       " 'Understanding of data analysis, data modeling, database design, data migration and business intelligence solutions.Experience in analyzing & validating data.',\n",
       " 'Anyone who is hungry to positively impact society using Artificial Intelligence (AI) & Machine Learning (ML).Some experience in Machine Learning.',\n",
       " 'This Data Scientist will focus on architecting, deploying and evaluating intelligent solutions as part of a growing Data Science team within Royal Caribbean.',\n",
       " '2+ years of experience as a data scientist or highly technical data analyst.Strong skills in data extraction and transformation with SQL.',\n",
       " 'The data scientist will also need to integrate data from disparate sources into an efficient and intuitive rational database structure.',\n",
       " 'Leverage data science tools and techniques to analyze large data sets and develop custom models/algorithms to uncover trends, patterns and insights in the data.',\n",
       " '(Includes Data Modeler, Data Miner.).You are responsible for data related activities such as data extraction, profiling, cleansing, de-duplication,…',\n",
       " '1-3 years of data warehousing ETL experience.Ensures databases and data extracts reflect specifications;Research applications development, data ontologies…',\n",
       " 'Strong knowledge of regression analysis, data science, and other statistical methods.Serve as an information resource for Ticket Operations and Ticket Sales on…',\n",
       " 'Perform data quality audits, identify data collection issues, suggest improvements and implement fixes.Daily data mining, and reporting.',\n",
       " 'Proven experience as a Data Scientist or Data Analyst.Graduate degree in Data Science or other quantitative field is preferred.What You’ll Get to Do:',\n",
       " 'Source, manipulate, cleanse and synthesis data at scale from disparate structured and unstructured data sources.Rated #1 Prepaid Wireless Provider in the U.S.',\n",
       " '1-3 years of data warehousing ETL experience.Ensures databases and data extracts reflect specifications;Research applications development, data ontologies…']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup): \n",
    "    summaries = []\n",
    "    style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\"\n",
    "    #spans = soup.findAll(\"div\", attrs={\"class\": \"summary\"})\n",
    "    for row in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for div in row.findAll(\"div\", attrs={\"class\": \"summary\"}):\n",
    "                for ul in div.findAll([\"ul\", \"/ul\"], attrs={\"style\": style}):\n",
    "                    summaries.append(ul.text.strip())\n",
    "                \n",
    "    return summaries\n",
    "extract_summary_from_result(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_results_per_city = 100\n",
    "city_set = [\"San+Francisco\", \"Washington+DC\",\"Austin\",\"Seattle\",\"Baltimore\",\"New+York\",\n",
    "            \"Miami\", \"Denver\", \"Portland\", \"Chicago\", \"Atlanta\", \"Seattle\", \"Los+Angeles\"]\n",
    "columns = [\"city\",\"job_title\",\"summary\"]\n",
    "sample_df = pd.DataFrame(columns = columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\U4-S1-NLP\\lib\\site-packages\\bs4\\__init__.py:191: UserWarning: You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\n",
      "  warnings.warn(\"You provided Unicode markup but also provided a value for from_encoding. Your from_encoding will be ignored.\")\n"
     ]
    }
   ],
   "source": [
    "#scraping code:\n",
    "for city in city_set:\n",
    "    for start in range(0, max_results_per_city, 10):\n",
    "        page = requests.get('http://www.indeed.com/jobs?q=data+scientist+junior&l=' + str(city) + '&start=' + str(start))\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\", from_encoding=\"utf-8\")\n",
    "        for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "            #specifying row num for index of job posting in dataframe\n",
    "            num = (len(sample_df) + 1)\n",
    "            #creating an empty list to hold the data for each posting\n",
    "            job_post = []\n",
    "            #append city name\n",
    "            job_post.append(city)\n",
    "            #grabbing job title\n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "                job_post.append(a[\"title\"])\n",
    "            #grabbing summary text\n",
    "            d = div.findAll(\"span\", attrs={\"class\":\"summary\"})\n",
    "#             for span in d:\n",
    "#                 job_post.append(span.text.strip())\n",
    "            style=\"list-style-type:circle;margin-top: 0px;margin-bottom: 0px;padding-left:20px;\"\n",
    "            for b in div.findAll(\"div\", attrs={\"class\": \"summary\"}):\n",
    "                for ul in b.findAll([\"ul\", \"/ul\"], attrs={\"style\": style}):\n",
    "                    job_post.append(ul.text.strip())\n",
    "            #appending list of job post info to dataframe at index num\n",
    "            sample_df.loc[num] = job_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Title: Principal Data Scientist - 61756.Work w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Biophysicist/Physical Chemist-PhD Degree Required</td>\n",
       "      <td>Lead and manage a small team (2-3 junior scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Sr. Scientist</td>\n",
       "      <td>Provide guidance and supervise junior research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Associate Director-CAR-T</td>\n",
       "      <td>Get up in front of senior partners and present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>The Jr. Data Scientist will dig into data to u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city                                          job_title  \\\n",
       "1  San+Francisco                           Principal Data Scientist   \n",
       "2  San+Francisco  Biophysicist/Physical Chemist-PhD Degree Required   \n",
       "3  San+Francisco                                      Sr. Scientist   \n",
       "4  San+Francisco                           Associate Director-CAR-T   \n",
       "5  San+Francisco                           Associate Data Scientist   \n",
       "\n",
       "                                             summary  \n",
       "1  Title: Principal Data Scientist - 61756.Work w...  \n",
       "2  Lead and manage a small team (2-3 junior scien...  \n",
       "3  Provide guidance and supervise junior research...  \n",
       "4  Get up in front of senior partners and present...  \n",
       "5  The Jr. Data Scientist will dig into data to u...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Title: Principal Data Scientist - 61756.Work with large geospatial data, including high resolution satellite imagery and environmental data.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.summary[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KcYlc1URXhlC"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "# raise Exception(\"\\nThis task is not complete. \\nReplace this line with your code for the task.\")\n",
    "                \n",
    "# from bs4 import BeautifulSoup\n",
    "# import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5C4xFZNtX1m2"
   },
   "source": [
    "## 2) Use Spacy to tokenize / clean the listings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhUHuMr-X-II"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lemmas(text):\n",
    "\n",
    "    lemmas = []\n",
    "    \n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # Something goes here :P\n",
    "    for token in doc: \n",
    "        if ((token.is_stop == False) and (token.is_punct == False)) and (token.pos_!= 'PRON'):\n",
    "            lemmas.append(token.lemma_)\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>job_title</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Title: Principal Data Scientist - 61756.Work w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Biophysicist/Physical Chemist-PhD Degree Required</td>\n",
       "      <td>Lead and manage a small team (2-3 junior scien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Sr. Scientist</td>\n",
       "      <td>Provide guidance and supervise junior research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Associate Director-CAR-T</td>\n",
       "      <td>Get up in front of senior partners and present...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>San+Francisco</td>\n",
       "      <td>Associate Data Scientist</td>\n",
       "      <td>The Jr. Data Scientist will dig into data to u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            city                                          job_title  \\\n",
       "1  San+Francisco                           Principal Data Scientist   \n",
       "2  San+Francisco  Biophysicist/Physical Chemist-PhD Degree Required   \n",
       "3  San+Francisco                                      Sr. Scientist   \n",
       "4  San+Francisco                           Associate Director-CAR-T   \n",
       "5  San+Francisco                           Associate Data Scientist   \n",
       "\n",
       "                                             summary  \n",
       "1  Title: Principal Data Scientist - 61756.Work w...  \n",
       "2  Lead and manage a small team (2-3 junior scien...  \n",
       "3  Provide guidance and supervise junior research...  \n",
       "4  Get up in front of senior partners and present...  \n",
       "5  The Jr. Data Scientist will dig into data to u...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sample_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lemmas'] = df['summary'].apply(get_lemmas)\n",
    "df_test = df['summary'].apply(get_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    [title, Principal, Data, Scientist, 61756.work...\n",
       "2    [lead, manage, small, team, 2, 3, junior, seek...\n",
       "3    [provide, guidance, supervise, junior, researc...\n",
       "4    [senior, partner, present, datum, manage, ment...\n",
       "5    [Jr., Data, Scientist, dig, datum, uncover, in...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lead and manage a small team (2-3 junior scientists).We are seeking a highly-motivated and risk-taking biophysicist/physical chemist to take a key role in…'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.summary[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead',\n",
       " 'manage',\n",
       " 'small',\n",
       " 'team',\n",
       " '2',\n",
       " '3',\n",
       " 'junior',\n",
       " 'seek',\n",
       " 'highly',\n",
       " 'motivated',\n",
       " 'risk',\n",
       " 'take',\n",
       " 'biophysicist',\n",
       " 'physical',\n",
       " 'chemist',\n",
       " 'key',\n",
       " 'role']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.lemmas[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_summary_lemmas = []\n",
    "for set_of_lemmas in df['lemmas'].values:\n",
    "    working_set = \"\"\n",
    "    for lemma in set_of_lemmas:\n",
    "        working_set += lemma + ' '\n",
    "    jobs_summary_lemmas.append(working_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title Principal Data Scientist 61756.work large geospatial datum include high resolution satellite imagery environmental datum ',\n",
       " 'lead manage small team 2 3 junior seek highly motivated risk take biophysicist physical chemist key role ',\n",
       " 'provide guidance supervise junior research associate aspect analytical laboratory operation sample receipt datum generation ',\n",
       " 'senior partner present datum manage mentor junior Scientists Associate organization aggressively build ',\n",
       " 'Jr. Data Scientist dig datum uncover insight design experiment measure impact contribute long term product strategy ',\n",
       " 'responsibility Data Scientist include qualification Data Scientist include compensation Data Scientist include ',\n",
       " 'provide coaching mentoring junior level datum scientist experience work following r Python SAS datum manipulation ',\n",
       " 'individual execute radiation health safety survey control process high technical datum integrity standard set forth ',\n",
       " 'convey idea guide execution mentor junior team member implement high quality datum science machine learning base product ',\n",
       " 'work multiple subject matter expert drive new datum initiative automation report establish good practice mentor junior member team ']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs_summary_lemmas[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-lgCZNL_YycP"
   },
   "source": [
    "## 3) Use Scikit-Learn's CountVectorizer to get word counts for each listing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2PZ8Pj_YxcF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>046713</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>20</th>\n",
       "      <th>2020</th>\n",
       "      <th>20407</th>\n",
       "      <th>21</th>\n",
       "      <th>24</th>\n",
       "      <th>30</th>\n",
       "      <th>...</th>\n",
       "      <th>writer</th>\n",
       "      <th>writing</th>\n",
       "      <th>wtih</th>\n",
       "      <th>www</th>\n",
       "      <th>xcalar</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>york</th>\n",
       "      <th>zerofox</th>\n",
       "      <th>zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1740 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  046713  10  11  20  2020  20407  21  24  30  ...  writer  writing  \\\n",
       "0   0       0   0   0   0     0      0   0   0   0  ...       0        0   \n",
       "1   0       0   0   0   0     0      0   0   0   0  ...       0        0   \n",
       "2   0       0   0   0   0     0      0   0   0   0  ...       0        0   \n",
       "3   0       0   0   0   0     0      0   0   0   0  ...       0        0   \n",
       "4   0       0   0   0   0     0      0   0   0   0  ...       0        0   \n",
       "\n",
       "   wtih  www  xcalar  year  years  york  zerofox  zone  \n",
       "0     0    0       0     0      0     0        0     0  \n",
       "1     0    0       0     0      0     0        0     0  \n",
       "2     0    0       0     0      0     0        0     0  \n",
       "3     0    0       0     0      0     0        0     0  \n",
       "4     0    0       0     0      0     0        0     0  \n",
       "\n",
       "[5 rows x 1740 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "vect = CountVectorizer(stop_words='english')\n",
    "vect.fit(jobs_summary_lemmas)\n",
    "dtm = vect.transform(jobs_summary_lemmas)\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=vect.get_feature_names())\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zo1iH_UeY7_n"
   },
   "source": [
    "## 4) Visualize the most common word counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwFsTqrVZMYi"
   },
   "source": [
    "## 5) Use Scikit-Learn's tfidfVectorizer to get a TF-IDF feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gx2gZCbl5Np"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "def tokenize(document):\n",
    "    doc = nlp(document)\n",
    "    return [token.lemma_.strip() for token in doc if (token.is_stop != True) and (token.is_punct != True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+</th>\n",
       "      <th>+ year</th>\n",
       "      <th>ability</th>\n",
       "      <th>algorithm</th>\n",
       "      <th>analysis</th>\n",
       "      <th>analyst</th>\n",
       "      <th>analytic</th>\n",
       "      <th>analytical</th>\n",
       "      <th>analyze</th>\n",
       "      <th>application</th>\n",
       "      <th>...</th>\n",
       "      <th>technical support</th>\n",
       "      <th>technology</th>\n",
       "      <th>tool</th>\n",
       "      <th>training</th>\n",
       "      <th>training technical</th>\n",
       "      <th>use</th>\n",
       "      <th>visualization</th>\n",
       "      <th>web</th>\n",
       "      <th>work</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.425028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     +  + year  ability  algorithm  analysis  analyst  analytic  analytical  \\\n",
       "0  0.0     0.0      0.0        0.0       0.0      0.0       0.0    0.000000   \n",
       "1  0.0     0.0      0.0        0.0       0.0      0.0       0.0    0.000000   \n",
       "2  0.0     0.0      0.0        0.0       0.0      0.0       0.0    0.425028   \n",
       "3  0.0     0.0      0.0        0.0       0.0      0.0       0.0    0.000000   \n",
       "4  0.0     0.0      0.0        0.0       0.0      0.0       0.0    0.000000   \n",
       "\n",
       "   analyze  application  ...  technical support  technology  tool  training  \\\n",
       "0      0.0          0.0  ...                0.0         0.0   0.0       0.0   \n",
       "1      0.0          0.0  ...                0.0         0.0   0.0       0.0   \n",
       "2      0.0          0.0  ...                0.0         0.0   0.0       0.0   \n",
       "3      0.0          0.0  ...                0.0         0.0   0.0       0.0   \n",
       "4      0.0          0.0  ...                0.0         0.0   0.0       0.0   \n",
       "\n",
       "   training technical  use  visualization  web  work  year  \n",
       "0                 0.0  0.0            0.0  0.0   0.0   0.0  \n",
       "1                 0.0  0.0            0.0  0.0   0.0   0.0  \n",
       "2                 0.0  0.0            0.0  0.0   0.0   0.0  \n",
       "3                 0.0  0.0            0.0  0.0   0.0   0.0  \n",
       "4                 0.0  0.0            0.0  0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Instantiate vectorizer object\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, min_df=0.025, max_df=.98, ngram_range=(1,2))\n",
    "# Create a vocabulary and get word counts per document\n",
    "dtm = tfidf.fit_transform(df.summary) # Similiar to fit_predict\n",
    "# Print word counts\n",
    "# Get feature names to use as dataframe column headers\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tfidf.get_feature_names())\n",
    "# View Feature Matrix as DataFrame\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Create a NearestNeighbor Model. Write the description of your ideal datascience job and query your job listings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "inputHidden": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "outputHidden": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "         metric_params=None, n_jobs=None, n_neighbors=5, p=2, radius=1.0)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Your Code Here #####\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Fit on TF-IDF Vectors\n",
    "nn  = NearestNeighbors(n_neighbors=5, algorithm='kd_tree')\n",
    "nn.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., 0., 0.]]),\n",
       " array([[ 88,   0,  45, 148,  30]], dtype=int64))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors([dtm.iloc[30]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experience building teams and coaching and mentoring more junior scientists.The team currently has research programs across several therapeutic areas,…'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.summary[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Experience building teams and coaching and mentoring more junior scientists.The team currently has research programs across several therapeutic areas,…'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.summary[88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_job_description = [\"junior small team good pay learning opportunity\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = tfidf.transform(ideal_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.97186169, 1.        , 1.02403518, 1.02403518, 1.02403518]]),\n",
       " array([[1196, 1265,   87,   32,  147]], dtype=int64))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.kneighbors(new.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Provide guidance and supervise junior research associates.All aspects of analytical laboratory operations, such as sample receipt, data generation,…'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df.summary[147]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FiDfTWceoRkH"
   },
   "source": [
    "## Stretch Goals\n",
    "\n",
    " - Try different visualizations for words and frequencies - what story do you want to tell with the data?\n",
    " - Scrape Job Listings for the job title \"Data Analyst\". How do these differ from Data Scientist Job Listings\n",
    " - Try and identify requirements for experience specific technologies that are asked for in the job listings. How are those distributed among the job listings?\n",
    " - Use a clustering algorithm to cluster documents by their most important terms. Do the clusters reveal any common themes?\n",
    "  - **Hint:** K-means might not be the best algorithm for this. Do a little bit of research to see what might be good for this. Also, remember that algorithms that depend on Euclidean distance break down with high dimensional data.\n",
    " - Create a labeled dataset - which jobs will you apply for? Train a model to select the jobs you are most likely to apply for. :) "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LS_DS_422_BOW_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "U4-S1-NLP (Python3)",
   "language": "python",
   "name": "u4-s1-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "nteract": {
   "version": "0.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
